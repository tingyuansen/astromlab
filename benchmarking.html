<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      AstroBench &middot; AstroMLab
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="./public/css/poole.css">
  <link rel="stylesheet" href="./public/css/syntax.css">
  <link rel="stylesheet" href="./public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="./atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          AstroMLab
        </a>
      </h1>
      <p class="lead">Steering astronomy into the age of autonomy! <br> Builder of AstroLLaMA and AstroSage</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="./index.html">Home</a>

      

      
      
        
      
        
          
            <a class="sidebar-nav-item active" href="./benchmarking.html">AstroBench</a>
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="./ollama.html">Running Models on Your Laptop</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="./why_astronomy.html">Why LLMs for Astronomy?</a>
          
        
      

      <a class="sidebar-nav-item" href="https://huggingface.co/AstroMLab">Download Models on Hugging Face</a> 
    </nav>

    <p>&copy; 2024. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="page">
        <h1 class="page-title">AstroBench</h1>
      <div class="page">
  <p>Our benchmarking dataset is <strong>available</strong> for <a href="https://huggingface.co/datasets/AstroMLab/Astrobench_MCQ_v1_Public"><strong>download</strong></a> on Hugging Face.</p>

<p>Exploring astronomy LLMs provides an unprecedented opportunity to quantify capabilities that were previously difficult to assess. The progress of astronomy requires a myriad of logical skills. These skills often combine elements of <em>factual retrieval</em>, <em>competitive mathematics derivation</em>, and <em>common sense AI</em>, making it challenging to assess LLM performance in this domain.</p>

<h2 id="addressing-the-gap-in-scientific-reasoning-datasets">Addressing the Gap in Scientific Reasoning Datasets</h2>

<p>Until recently, there was a <strong>void</strong> in <em>question and answering datasets</em> specifically tailored to scientific reasoning in astronomy. To address this gap, we have focused on <strong>establishing the standard for astronomical Q&amp;A</strong> in this non-trivial and largely unexplored field.</p>

<h2 id="our-benchmarking-dataset">Our Benchmarking Dataset</h2>

<p>In collaboration with Argonne National Laboratory, we have developed a comprehensive astronomical benchmarking dataset, designed to evaluate LLM performance in astronomical research contexts. This dataset comprises both Q&amp;A and Multiple Choice Question (MCQ) components. Key features include:</p>

<ul>
  <li><strong>Source</strong>: 885 articles from the Annual Review of Astronomy and Astrophysics (ARAA), 1963-2023</li>
  <li><strong>Quality Control</strong>:
    <ul>
      <li>Questions are specific to article content but general enough for independent use</li>
      <li>Answers are general, not pointing to specific sections</li>
      <li>Answer options are balanced in length</li>
    </ul>
  </li>
  <li><strong>Explanation and Citation</strong>: Each question includes an explanation and supporting paragraphs from the review</li>
  <li><strong>Human Validation</strong>: Experts reviewed a subset of questions to ensure adequacy</li>
</ul>

<p>This dataset is designed to:</p>

<ul>
  <li>Evaluate LLM performance in astronomical research contexts</li>
  <li>Test astronomical facts and community consensus</li>
  <li>Assess models‚Äô abilities to link insights across diverse subfields</li>
  <li>Gauge understanding of the interdisciplinary nature of astronomical research</li>
</ul>

<h2 id="example-questions">Example Questions</h2>

<p>Here are some examples from our dataset:</p>

<div style="background-color: #e6f3ff; padding: 15px; margin-bottom: 15px; border-radius: 5px;">
<strong>Topic: Quasar Number Density</strong><br />
<br />

<strong>Question:</strong> What is the primary reason for the decline in the number density of luminous quasars at redshifts greater than 5?<br />
<br />

<strong>A)</strong> A decrease in the overall star formation rate, leading to fewer potential host galaxies for quasars. <br />

<strong>B)</strong> An increase in the neutral hydrogen fraction in the intergalactic medium, which obscures the quasars' light. <br />

<strong>C)</strong> A decrease in the number of massive black hole seeds that can form and grow into supermassive black holes. <br />

<strong>D)</strong> An increase in the average metallicity of the Universe, leading to a decrease in the efficiency of black hole accretion. <br />

<br />
<strong>Correct Answer:</strong> C
</div>

<div style="background-color: #fff0e6; padding: 15px; margin-bottom: 15px; border-radius: 5px;">
<strong>Topic: Cosmological Simulations</strong><br />
<br />

<strong>Question:</strong> What is the primary goal of calibrating subgrid feedback models in cosmological simulations?<br />
<br />

<strong>A)</strong> To ensure that simulations accurately reproduce the observed properties of the interstellar medium.<br />

<strong>B)</strong> To create a diverse range of galaxy morphologies in the simulations.<br />

<strong>C)</strong> To achieve convergence in simulation results across different resolutions and box sizes.<br />

<strong>D)</strong> To steer simulations towards producing a broadly realistic galaxy population that is consistent with key observational constraints.<br />

<br />
<strong>Correct Answer:</strong> D
</div>

<div style="background-color: #e6ffe6; padding: 15px; margin-bottom: 15px; border-radius: 5px;">
<strong>Topic: Circumgalactic Medium</strong><br />
<br />

<strong>Question:</strong> The properties of the circumgalactic medium (CGM) primarily depend on the competition between: <br />
<br />

<strong>A)</strong> Star formation rate and supernova feedback.<br />

<strong>B)</strong> Gas cooling and stellar winds.<br />

<strong>C)</strong> Gravity-driven infall and gas cooling. <br />

<strong>D)</strong> Magnetic fields and thermal conduction. <br />

<br />
<strong>Correct Answer:</strong> C
</div>

<p>These examples demonstrate the depth and breadth of astronomical knowledge covered in our benchmarking dataset.</p>

<h2 id="benchmarking-results">Benchmarking Results</h2>

<p>Our benchmarking results reveal significant variations in performance across different proprietary large language models when tested on astronomy-specific questions. For a comprehensive analysis and detailed discussion of these results, please refer to <a href="https://arxiv.org/abs/2407.11194">Ting et al. (2024)</a>.</p>

<h3 id="open-weights-models">Open-Weights Models</h3>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Score (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>AstroMLab/AstroSage Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td><span style="color: #3366cc;">AstroSage-8B (AstroMLab, de Haan et al., 2024)</span></td>
      <td><span style="color: #3366cc;">80.9 ‚ñ≤ ‚ñ≤ ‚ñ≤ </span> ü•à</td>
    </tr>
    <tr>
      <td><strong>Meta/LLaMA Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>LLaMA-2-7B</td>
      <td>50.3</td>
    </tr>
    <tr>
      <td><span style="color: #3366cc;">AstroLLaMA-2-7B (UniverseTBD, Perkowski et al., 2024)</span></td>
      <td><span style="color: #3366cc;">44.3</span> üîª</td>
    </tr>
    <tr>
      <td>LLaMA-2-70B</td>
      <td>70.7</td>
    </tr>
    <tr>
      <td><span style="color: #3366cc;">AstroLLaMA-2-70B (AstroMLab, Pan et al., 2024)</span></td>
      <td><span style="color: #3366cc;">72.3 ‚ñ≤ </span></td>
    </tr>
    <tr>
      <td>LLaMA-3-8B</td>
      <td>72.9</td>
    </tr>
    <tr>
      <td>LLaMA-3-70B</td>
      <td>80.4</td>
    </tr>
    <tr>
      <td>LLaMA-3.1-8B</td>
      <td>73.7</td>
    </tr>
    <tr>
      <td>LLaMA-3.1-70B</td>
      <td>80.1</td>
    </tr>
    <tr>
      <td>LLaMA-3.1-405B</td>
      <td><strong>83.8</strong> ü•á</td>
    </tr>
    <tr>
      <td>LLaMA-3.2-11B</td>
      <td>74.9</td>
    </tr>
    <tr>
      <td>LLaMA-3.2-90B</td>
      <td>80.6 ü•â</td>
    </tr>
    <tr>
      <td><strong>Mistral AI Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Mistral-7B-v0.1</td>
      <td>48.1</td>
    </tr>
    <tr>
      <td>Mistral-8x7B-v0.1</td>
      <td>73.7</td>
    </tr>
    <tr>
      <td>Mixtral-8x22B-v0.1</td>
      <td>77.7</td>
    </tr>
    <tr>
      <td>Mistral-7B-v0.2</td>
      <td>62.1</td>
    </tr>
    <tr>
      <td>Mistral-7B-v0.3</td>
      <td>63.9</td>
    </tr>
    <tr>
      <td>Mistral-12B-Nemo</td>
      <td>71.6</td>
    </tr>
    <tr>
      <td><strong>Microsoft/Phi Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Phi-2-3B</td>
      <td>65.6</td>
    </tr>
    <tr>
      <td>Phi-3-4B</td>
      <td>71.7</td>
    </tr>
    <tr>
      <td>Phi-3-14B</td>
      <td>75.6</td>
    </tr>
    <tr>
      <td>Phi-3.5-4B</td>
      <td>72.8</td>
    </tr>
    <tr>
      <td><strong>Google/Gemma Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Gemma-2-2B</td>
      <td>58.5</td>
    </tr>
    <tr>
      <td>Gemma-2-9B</td>
      <td>71.5</td>
    </tr>
    <tr>
      <td>Gemma-2-27B</td>
      <td>75.3</td>
    </tr>
    <tr>
      <td><strong>Alibaba/Qwen(ÈÄö‰πâÂçÉÈóÆ) Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Qwen-2.5-7B</td>
      <td>70.4</td>
    </tr>
    <tr>
      <td>Qwen-2.5-72B</td>
      <td>78.6</td>
    </tr>
    <tr>
      <td><strong>Nvidia/Nemotron Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Nemotron-340B</td>
      <td>80.6 ü•â</td>
    </tr>
    <tr>
      <td><strong>01/Yi(Èõ∂‰∏Ä‰∏áÁâ©) Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Yi-1.5-6B</td>
      <td>61.0</td>
    </tr>
    <tr>
      <td>Yi-1.5-9B</td>
      <td>68.4</td>
    </tr>
    <tr>
      <td>Yi-1.5-34B</td>
      <td>73.1</td>
    </tr>
    <tr>
      <td><strong>Deepseek(Ê∑±Â∫¶Ê±ÇÁ¥¢) Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Deepseek-67B</td>
      <td>63.1</td>
    </tr>
    <tr>
      <td><strong>Zhipu(Êô∫Ë∞±)/ChatGLM Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>ChatGLM3-6B</td>
      <td>50.4</td>
    </tr>
    <tr>
      <td>GLM-4-9B</td>
      <td>67.0</td>
    </tr>
    <tr>
      <td><strong>PJ Lab(Êµ¶ËØ≠)/InternLM(‰π¶Áîü) Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>InternLM-2.5-7B</td>
      <td>64.5</td>
    </tr>
    <tr>
      <td>InternLM-2.5-20B</td>
      <td>66.7</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="proprietary-models">Proprietary Models</h3>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Score (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>OpenAI/GPT Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>O1-Mini</td>
      <td>80.1</td>
    </tr>
    <tr>
      <td>O1-Preview</td>
      <td>81.6 ü•â</td>
    </tr>
    <tr>
      <td>GPT-3.5</td>
      <td>70.4</td>
    </tr>
    <tr>
      <td>GPT-4</td>
      <td>74.5</td>
    </tr>
    <tr>
      <td>GPT-4o-Mini</td>
      <td>76.1</td>
    </tr>
    <tr>
      <td>GPT-4o</td>
      <td>80.4</td>
    </tr>
    <tr>
      <td><strong>Anthropic/Claude Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Claude-2.0</td>
      <td>75.3</td>
    </tr>
    <tr>
      <td>Claude-3.0-Haiku</td>
      <td>77.9</td>
    </tr>
    <tr>
      <td>Claude-3.0-Sonnet</td>
      <td>76.7</td>
    </tr>
    <tr>
      <td>Claude-3.0-Opus</td>
      <td>82.7 ü•à</td>
    </tr>
    <tr>
      <td>Claude-3.5-Sonnet</td>
      <td><strong>85.0</strong> ü•á</td>
    </tr>
    <tr>
      <td><strong>Google/Gemini Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Gemini-1.0-Pro-001</td>
      <td>71.0</td>
    </tr>
    <tr>
      <td>Gemini-1.5-Flash-001</td>
      <td>73.6</td>
    </tr>
    <tr>
      <td>Gemini-1.5-Pro-001</td>
      <td>77.6</td>
    </tr>
    <tr>
      <td>Gemini-1.5-Flash-002</td>
      <td>76.5</td>
    </tr>
    <tr>
      <td>Gemini-1.5-Pro-002</td>
      <td>78.2</td>
    </tr>
    <tr>
      <td><strong>Mistral AI Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Mistral-Large-1</td>
      <td>76.4</td>
    </tr>
    <tr>
      <td>Mistral-Large-2</td>
      <td>80.8</td>
    </tr>
    <tr>
      <td><strong>xAI Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Grok-Beta</td>
      <td>79.5</td>
    </tr>
    <tr>
      <td><strong>Zhipu(Êô∫Ë∞±)/GLM Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>GLM-3-Turbo</td>
      <td>64.3</td>
    </tr>
    <tr>
      <td>GLM-4-Flash</td>
      <td>67.1</td>
    </tr>
    <tr>
      <td>GLM-4-Air</td>
      <td>72.9</td>
    </tr>
    <tr>
      <td>GLM-4-AirX</td>
      <td>72.5</td>
    </tr>
    <tr>
      <td>GLM-4-0520</td>
      <td>75.1</td>
    </tr>
    <tr>
      <td>GLM-4-Plus</td>
      <td>77.9</td>
    </tr>
    <tr>
      <td><strong>Baidu/ERNIE(ÊñáÂøÉ‰∏ÄË®Ä) Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>ERNIE-3.5</td>
      <td>72.1</td>
    </tr>
    <tr>
      <td>ERNIE-4.0</td>
      <td>75.1</td>
    </tr>
    <tr>
      <td><strong>Deepseek(Ê∑±Â∫¶Ê±ÇÁ¥¢) Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Deepseek-v2</td>
      <td>73.6</td>
    </tr>
    <tr>
      <td>Deepseek-v2.5</td>
      <td>73.9</td>
    </tr>
    <tr>
      <td><strong>Step(Èò∂Ë∑ÉÊòüËæ∞) Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Step-1</td>
      <td>75.2</td>
    </tr>
    <tr>
      <td>Step-2</td>
      <td>80.5</td>
    </tr>
    <tr>
      <td><strong>ByteDance/Doubao(Ë±ÜÂåÖ) Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Doubao-Lite</td>
      <td>60.5</td>
    </tr>
    <tr>
      <td>Doubao-Pro</td>
      <td>70.1</td>
    </tr>
    <tr>
      <td><strong>MiniMax AI Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>ABAB-5.5</td>
      <td>69.5</td>
    </tr>
    <tr>
      <td>ABAB-6.5</td>
      <td>72.7</td>
    </tr>
    <tr>
      <td><strong>01/Yi(Èõ∂‰∏Ä‰∏áÁâ©) Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Yi-Medium</td>
      <td>70.3</td>
    </tr>
    <tr>
      <td>Yi-Large</td>
      <td>77.3</td>
    </tr>
    <tr>
      <td>Yi-Lightning</td>
      <td>78.0</td>
    </tr>
    <tr>
      <td><strong>Moonshot(Êúà‰πãÊöóÈù¢)/Kimi Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Moonshot-v1</td>
      <td>72.3</td>
    </tr>
    <tr>
      <td><strong>Perplexity Series</strong></td>
      <td>¬†</td>
    </tr>
    <tr>
      <td>Perplexity-Llama-3.1-Sonar-Small</td>
      <td>72.0</td>
    </tr>
    <tr>
      <td>Perplexity-Llama-3.1-Sonar-Large</td>
      <td>76.7</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h3 id="cost-and-performance-trade-off-in-astronomical-qa">Cost and Performance Trade-off in Astronomical Q&amp;A</h3>

<p>Cost efficiency is crucial when deploying LLMs as research agents in astronomy. The figure below illustrates the cost-performance relationship across various models.</p>

<p><img src="figures/AstroBench.png" alt="Cost and performance trade-off in astronomical Q&amp;A" /></p>

<p><strong>Figure:</strong> Our flagship model, AstroSage-LLaMA-3.1-8B, demonstrates exceptional performance in astronomical knowledge recall, achieving 80.9% accuracy on the AstroMLab-1 benchmark. This performance is comparable to OpenAI‚Äôs latest GPT-4o model and represents a substantial 8-point improvement over its base LLaMA-3.1-8B model.</p>

</div>

      </div>
    </div>

  </body>
</html>
