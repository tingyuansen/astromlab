<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Who is AstroMLab &middot; AstroMLab
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="./public/css/poole.css">
  <link rel="stylesheet" href="./public/css/syntax.css">
  <link rel="stylesheet" href="./public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="./atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          AstroMLab
        </a>
      </h1>
      <p class="lead">Steering astronomy into the age of autonomy! <br> Builder of AstroLLaMA</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item active" href="./index.html">Home</a>

      

      
      
        
      
        
          
            <a class="sidebar-nav-item" href="./benchmarking.html">Benchmarking</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="./goal.html">Our Goal</a>
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="./ollama.html">Running Models on Your Laptops</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="./why_astronomy.html">Why LLMs for Astronomy?</a>
          
        
      

      <a class="sidebar-nav-item" href="https://huggingface.co/AstroMLab">Download Models on Hugging Face</a> 
    </nav>

    <p>&copy; 2024. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="page">
        <h1 class="page-title">Who is AstroMLab</h1>
      <p>Welcome to <strong>AstroMLab</strong>, a dynamic group of <em>astronomers</em> and <em>computer scientists</em> who are passionate about pushing the boundaries of <strong>Large Language Models (LLMs)</strong> in astronomy. Our team is comprised of <em>leading astronomers</em>, <em>top natural language processing experts</em> from <em>Oak Ridge National Laboratory</em> and <em>Argonne National Laboratory</em>, and <em>frontier arXivists</em> from the <em>NASA Astrophysics Data System</em> who possess deep insights into the vast astronomy literature corpus. We are also fortunate to have a group of <em>enthusiastic young researchers</em> who are <strong>fearlessly bridging the gap between astronomy and LLMs</strong>.</p>

<p>We are grateful for the support we receive, including access to the <em>massive computing power</em> of the <strong>Frontier nodes at Oak Ridge</strong> and the backing of <strong>Microsoft Research</strong> for our project. While the field of LLMs is advancing at a breakneck pace, we firmly believe that real progress in <em>AI-driven scientific research</em>, particularly in astronomy, requires <em>deep domain knowledge</em>. However, such efforts are still largely lacking in astronomy, which has compelled us to unite and tackle this challenge head-on.</p>

<p>Despite being a relatively young group, we have already made significant strides. We have published the first LLM in astronomy, known as <strong>AstroLLaMA-7b</strong> and <strong>AstroLLaMA-chat-7b</strong> (previously part of <em>UniverseTBD</em>, but the core team of AstroLLaMA has since moved on). Most recently, we have released <strong>AstroLLaMA-70b</strong>, all of which were based on <em>LLaMa-2 models</em>. We have also built upon that to create a complete <em>“arena models”</em> by performing full-parameter fine-tuning on <strong>Phi-2</strong>, <strong>Phi-3</strong>, <strong>Mistral-7b</strong>, <strong>LLaMa-3b-8b</strong>, and <strong>QWen-7b</strong>.</p>

<p>Our team is rapidly expanding, and we would love to hear from you! Feel free to reach out to us at <strong><a href="yuan-sen.ting@anu.edu.au">here</a></strong>.</p>

<p>We are also fully committed to <strong>open source</strong> – all our models are immediately released on <strong>Hugging Face</strong>, and you can find all our models <strong><a href="https://huggingface.co/AstroMLab">here</a></strong>.</p>

<p><br /></p>

<hr />

<h2 id="team">Team</h2>

<table>
  <tr>
    <td align="center" width="25%"><img src="figures/Members_Yuan-Sen_Ting.png" alt="Yuan-Sen Ting" /></td>
    <td align="center" width="25%"><img src="figures/Members_Rui_Pan.png" alt="Rui Pan" /></td>
    <td align="center" width="25%"><img src="figures/Members_Josh_Nguyen.png" alt="Josh Nguyen" /></td>
    <td align="center" width="25%"><img src="figures/Members_Hardik_Arora.png" alt="Hardik Arora" /></td>
  </tr>
  <tr>
    <td align="center"><strong>Yuan-Sen Ting</strong><br />Australian National University</td>
    <td align="center"><strong>Rui Pan</strong><br />University of Illinois Urbana-Champaign</td>
    <td align="center"><strong>Josh Nguyen</strong><br />University of Pennsylvania</td>
    <td align="center"><strong>Hardik Arora</strong><br />Indian Institutes of Technology</td>
  </tr>
  <tr>
    <td align="center"><img src="figures/Members_Zechang_Sun.png" alt="Zechang Sun" /></td>
    <td align="center"><img src="figures/Members_Tirthankar_Ghosal.png" alt="Tirthankar Ghosal" /></td>
    <td align="center"><img src="figures/Members_Alberto_Accomazzi.png" alt="Alberto Accomazzi" /></td>
    <td align="center"><img src="figures/Members_Yuwei_Yang.png" alt="Yuwei Yang" /></td>
  </tr>
  <tr>
    <td align="center"><strong>Zechang Sun</strong><br />Tsinghua Unversity</td>
    <td align="center"><strong>Tirthankar Ghosal</strong><br />Oak Ridge National Laboratory</td>
    <td align="center"><strong>Alberto Accomazzi</strong><br />NASA Astrophysics Data System</td>
    <td align="center"><strong>Yuwei Yang</strong><br />Australian National University</td>
  </tr>
  <tr>
    <td align="center"><img src="figures/Members_Tirthankar_Ghosal.png" alt="Azton Wells" /></td>
    <td align="center"><img src="figures/Members_Alberto_Accomazzi.png" alt="Nesar Ramachandra" /></td>
    <td align="center"><img src="figures/Members_Alberto_Accomazzi.png" alt="Sandeep Madireddy" /></td>
  </tr>
  <tr>
    <td align="center"><strong>Azton Wells</strong><br />Argonne National Laboratory</td>
    <td align="center"><strong>Nesar Ramachandra</strong><br />Argonne National Laboratory</td>
    <td align="center"><strong>Sandeep Madireddy</strong><br />Argonne National Laboratory</td>
  </tr>
</table>

<p><br /></p>

<hr />

<h2 id="key-outputs-1-the-astrollama-series">Key Outputs 1: The AstroLLaMA Series</h2>

<p><strong><a href="https://arxiv.org/abs/2309.06126">Josh Nguyen, Yuan-Sen Ting et al., 2023, arXiv:2309.06126</a></strong></p>

<p><strong><a href="https://arxiv.org/abs/2401.01916">Ernest Perkowski, Rui Pan, Josh Nguyen, et al., 2024, arXiv:2401.01916</a></strong></p>

<p><img src="figures/Figure_AstroLLaMa_Logo.png" alt="" width="50%" /></p>

<p>Our study introduces the pioneering <strong>AstroLLaMA</strong> series, featuring the cutting-edge models <em>AstroLLaMA-7b</em>, <em>AstroLLaMA-7b-Chat</em>, and the expansive <em>AstroLLaMA-70b</em>. These state-of-the-art language models are the result of full parameter fine-tuning from LLaMA-2 using the entire corpus of astronomy arXiv. The training of the AstroLLaMA series incorporates conversational capabilities and diverse, curated question-answering datasets pertinent to astronomy, enhancing its performance in astronomy-focused question-answering tasks.</p>

<p>AstroLLaMA-Chat stands as the <strong>first open-source conversational AI tool</strong> tailored specifically for the astronomy community. To the best of our knowledge, this also marks the <strong>first-ever publicly available specialized LLM in astronomy</strong>, setting a new standard in the field.</p>

<p>Even with the 7b models, we demonstrate that AstroLLaMA achieves a remarkable <strong>30% lower perplexity</strong> compared to LLaMA-2. This substantial reduction in perplexity highlights the model’s successful domain adaptation and its potential to generate more insightful and scientifically relevant text completions.</p>

<p>AstroLLaMA’s <strong>embedding space</strong> exhibits a higher quality in reflecting <strong>semantic similarities</strong> among astronomy texts. Compared to other embedding models, our model demonstrates a more <em>granular representation</em> of astronomical content, facilitating enhanced <em>retrieval augmented generation</em>.</p>

<p><br /></p>

<hr />

<h2 id="key-outputs-2-the-mid-size-specialized-astronomy-models-arena">Key Outputs 2: The mid-size specialized Astronomy models Arena!</h2>

<p>Coming soon.</p>


      </div>
    </div>

  </body>
</html>
