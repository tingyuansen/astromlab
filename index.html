<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Welcome to AstroMLab &middot; AstroMLab
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="./public/css/poole.css">
  <link rel="stylesheet" href="./public/css/syntax.css">
  <link rel="stylesheet" href="./public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="./atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          AstroMLab
        </a>
      </h1>
      <p class="lead">Steering astronomy into the age of autonomy! <br> Builder of AstroLLaMA and AstroSage</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item active" href="./index.html">Home</a>

      

      
      
        
      
        
          
            <a class="sidebar-nav-item" href="./benchmarking.html">AstroBench</a>
          
        
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="./ollama.html">Running Models on Your Laptop</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="./why_astronomy.html">Why LLMs for Astronomy?</a>
          
        
      

      <a class="sidebar-nav-item" href="https://huggingface.co/AstroMLab">Download Models on Hugging Face</a> 
    </nav>

    <p>&copy; 2024. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="page">
        <h1 class="page-title">Welcome to AstroMLab</h1>
      <h2 id="who-we-are">Who We Are</h2>

<p>AstroMLab is a dynamic group of <em>astrophysicists</em> and <em>computer scientists</em> developing <strong>Large Language Models (LLMs) for astronomy</strong>. Our team includes:</p>

<ul>
  <li><em>Leading astronomers, astrophysicists, and cosmologists</em></li>
  <li><em>Top natural language processing experts</em> from Oak Ridge National Laboratory and Argonne National Laboratory</li>
  <li><em>Frontier arXivists</em> from the NASA Astrophysics Data System</li>
  <li><em>Enthusiastic young researchers</em> bridging astronomy and LLMs</li>
</ul>

<h2 id="our-goals">Our Goals</h2>

<ol>
  <li>Develop specialized LLMs for astronomy</li>
  <li>Create <strong>reliable, light-weight, and open-source models</strong> for research agents</li>
  <li><strong>Expedite scientific discovery</strong> through LLM-driven research</li>
  <li>Push the boundaries of astronomical research</li>
</ol>

<h2 id="our-outputs">Our Outputs</h2>

<p>We've achieved:</p>

<ul>
  <li>The <strong>first astronomy-based benchmarking dataset</strong> (<a href="https://arxiv.org/abs/2407.11194">Ting et al. 2024</a>)</li>
  <li>Released five model sets:
    <ul>
      <li><strong>AstroSage-LLaMA-3.1-70B</strong> (<a href="https://arxiv.org/abs/2505.17592">de Haan et al. 2025b</a>)</li>
      <li><strong>AstroSage-LLaMA-3.1-8B</strong> (<a href="https://arxiv.org/abs/2411.09012">de Haan et al. 2025a</a>)</li>
      <li><strong>AstroLLaMA-2-70B</strong> (<a href="https://arxiv.org/abs/2407.11194">Pan et al. 2024</a>)</li>
      <li><strong>AstroLLaMA-3-8B</strong> (<a href="https://arxiv.org/abs/2407.11194">Pan et al. 2024</a>)</li>
      <li>AstroLLaMA-2-7B (<a href="https://arxiv.org/abs/2401.01916">Perkowski et al. 2024</a>, <a href="https://arxiv.org/abs/2309.06126">Nguyen et al. 2023</a>)</li>
    </ul>
  </li>
</ul>

<p>Our flagship models, AstroSage-LLaMA-3.1-70B and AstroSage-LLaMA-3.1-8B, achieve 86.2% and 80.9% accuracy respectively on the AstroMLab-1 benchmark. The 70B model ties with Claude-4-Opus for the highest performance, while the 8B model performs comparably to Mistral-Large-v2 at a fraction of the cost (see <a href="benchmarking.html">AstroBench</a>).</p>

<table>
  <thead>
    <tr>
      <th>Model</th>
      <th>Score (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong><span style="color: #3366cc;">AstroSage-LLaMA-3.1-70B (AstroMLab)</span></strong></td>
      <td><strong><span style="color: #3366cc;">86.2</span></strong></td>
    </tr>
    <tr>
      <td>Claude-4-Opus</td>
      <td>86.3</td>
    </tr>
    <tr>
      <td>o3</td>
      <td>85.4</td>
    </tr>
    <tr>
      <td>Claude-4-Sonnet</td>
      <td>85.0</td>
    </tr>
    <tr>
      <td>GPT-4.1</td>
      <td>84.7</td>
    </tr>
    <tr>
      <td>o4-Mini</td>
      <td>84.7</td>
    </tr>
    <tr>
      <td>Gemini-2.5-Pro</td>
      <td>84.8</td>
    </tr>
    <tr>
      <td>Deepseek-R1</td>
      <td>84.4</td>
    </tr>
    <tr>
      <td>Qwen-3-235B</td>
      <td>84.0</td>
    </tr>
    <tr>
      <td>LLaMA-4-Maverick</td>
      <td>83.4</td>
    </tr>
    <tr>
      <td>Deepseek-v3-2503</td>
      <td>82.9</td>
    </tr>
    <tr>
      <td>Gemini-2.5-Flash-0520</td>
      <td>82.3</td>
    </tr>
    <tr>
      <td>LLaMA-4-Scout</td>
      <td>82.2</td>
    </tr>
    <tr>
      <td>Grok-3</td>
      <td>81.7</td>
    </tr>
    <tr>
      <td>Mistral-Medium-v3</td>
      <td>81.8</td>
    </tr>
    <tr>
      <td><strong><span style="color: #3366cc;">AstroSage-LLaMA-3.1-8B (AstroMLab)</span></strong></td>
      <td><strong><span style="color: #3366cc;">80.9</span></strong></td>
    </tr>
    <tr>
      <td>Mistral-Large-v2</td>
      <td>80.8</td>
    </tr>
    <tr>
      <td>Qwen-3-32B</td>
      <td>79.7</td>
    </tr>
    <tr>
      <td>Mistral-Small-v3.1</td>
      <td>78.6</td>
    </tr>
    <tr>
      <td>GPT-4.1-Nano</td>
      <td>78.0</td>
    </tr>
    <tr>
      <td>Gemini-2-Flash-Lite</td>
      <td>78.4</td>
    </tr>
    <tr>
      <td>Gemma-3-27B</td>
      <td>76.9</td>
    </tr>
    <tr>
      <td>Qwen-3-14B</td>
      <td>76.4</td>
    </tr>
    <tr>
      <td>AstroLLaMA-2-7B</td>
      <td>44.3</td>
    </tr>
  </tbody>
</table>

<p><img src="figures/AstroBench.png" alt="Cost and performance trade-off in astronomical Q&amp;A" /></p>

<h2 id="open-source-commitment">Open Source Commitment</h2>

<p>All our models are available on <a href="https://huggingface.co/AstroMLab">Hugging Face</a></p>

<h2 id="our-support">Our Support</h2>

<ul>
  <li>Access to Frontier nodes at Oak Ridge Leadership Computing Facility</li>
  <li>Microsoft’s Accelerating Foundation Models Research (AFMR)</li>
</ul>

<h2 id="join-us">Join Us</h2>

<p>Contact us: <a href="mailto:astromachinelearninglab@gmail.com">astromachinelearninglab@gmail.com</a></p>

<p><br /></p>

<hr />

<h2 id="team">Team</h2>

<table>
  <tr>
    <td align="center" width="25%"><img src="figures/Members_Yuan-Sen_Ting.png" alt="Yuan-Sen Ting" /></td>
    <td align="center" width="25%"><img src="figures/Members_Tirthankar_Ghosal.png" alt="Tirthankar Ghosal" /></td>
    <td align="center" width="25%"><img src="figures/Members_Tijmen_de_Haan.png" alt="Tijmen de Haan" /></td>
    <td align="center" width="25%"><img src="figures/Members_Josh_Nguyen.png" alt="Josh Nguyen" /></td>
  </tr>
  <tr>
    <td align="center"><strong>Yuan-Sen Ting</strong><br />The Ohio State University</td>
    <td align="center"><strong>Tirthankar Ghosal</strong><br />Oak Ridge National Laboratory</td>
    <td align="center"><strong>Tijmen de Haan</strong><br />KEK</td>
    <td align="center"><strong>Josh Nguyen</strong><br />University of Pennsylvania</td>
  </tr>
  <tr>
    <td align="center"><img src="figures/Members_Rui_Pan.png" alt="Rui Pan" /></td>
    <td align="center"><img src="figures/Members_Hardik_Arora.png" alt="Hardik Arora" /></td>
    <td align="center"><img src="figures/Members_Emily_Herron.png" alt="Emily Herron" /></td>
    <td align="center"><img src="figures/Members_Yuwei_Yang.png" alt="Yuwei Yang" /></td>
  </tr>
  <tr>
    <td align="center"><strong>Rui Pan</strong><br />University of Illinois Urbana-Champaign</td>
    <td align="center"><strong>Hardik Arora</strong><br />Indian Institutes of Technology</td>
    <td align="center"><strong>Emily Herron</strong><br />Oak Ridge National Laboratory</td>
    <td align="center"><strong>Yuwei Yang</strong><br />Australian National University</td>
  </tr>
  <tr>
    <td align="center"><img src="figures/Members_Zechang_Sun.png" alt="Alberto Accomazzi" /></td>
    <td align="center"><img src="figures/Members_Alberto_Accomazzi.png" alt="Alberto Accomazzi" /></td>
    <td align="center"><img src="figures/Members_Argonne.png" alt="Azton Wells" /></td>
    <td align="center"><img src="figures/Members_Nesar_Ramachandra.png" alt="Nesar Ramachandra" /></td>
    <td align="center"><img src="figures/Members_Sandeep_Madireddy.png" alt="Sandeep Madireddy" /></td>
  </tr>
  <tr>
    <td align="center"><strong>Zechang Sun</strong><br />Tsinghua University</td>
    <td align="center"><strong>Alberto Accomazzi</strong><br />NASA Astrophysics Data System</td>
    <td align="center"><strong>Azton Wells</strong><br />Argonne National Laboratory</td>
    <td align="center"><strong>Nesar Ramachandra</strong><br />Argonne National Laboratory</td>
  </tr>
  <tr>
    <td align="center"><img src="figures/Members_Sandeep_Madireddy.png" alt="Sandeep Madireddy" /></td>
  </tr>
  <tr>
    <td align="center"><strong>Sandeep Madireddy</strong><br />Argonne National Laboratory</td>
  </tr>
</table>

<p><br /></p>

<hr />

<h2 id="publications">Publications</h2>

<h3 id="astromlab-4-benchmark-topping-performance-in-astronomy-qa-with-70b-parameter-domain-specialized-reasoning-model">AstroMLab 4: Benchmark-Topping Performance in Astronomy Q&A with a 70B-Parameter Domain-Specialized Reasoning Model</h3>

<p><strong><a href="https://arxiv.org/abs/2505.17592">Tijmen de Haan, et al., 2025b</a></strong></p>

<p>We present AstroSage-LLaMA-3.1-70B, a 70-billion parameter domain-specialized language model that achieves state-of-the-art performance on astronomical knowledge tasks. Built from Meta-Llama-3.1-70B through extensive continued pre-training on astronomical literature, supervised fine-tuning, and model merging, it demonstrates that domain specialization can enable specialized models to outperform even the most advanced commercial alternatives.</p>

<p>Key points:</p>
<ul>
  <li>Achieved 86.2% accuracy on Astrobench, outperforming all tested models including o3, GPT-4.1, Claude-3.7-Sonnet, and Gemini-2.5-Pro</li>
  <li>Demonstrates ~100× improvement in cost-efficiency compared to achieving similar performance with general-purpose models</li>
  <li>Incorporates explicit reasoning capabilities that can be activated for complex multi-step astronomical analysis</li>
  <li>Openly available under Llama 3.1 Community License to accelerate AI adoption in astronomy research and education</li>
</ul>

<p><br /></p>

<h3 id="astromlab-3-achieving-gpt-4o-level-performance-in-astronomy-with-a-specialized-8b-parameter-large-language-model">AstroMLab 3: Achieving GPT-4o Level Performance in Astronomy with a Specialized 8B-Parameter Large Language Model</h3>

<p><strong><a href="https://arxiv.org/abs/2411.09012">Tijmen de Haan, et al., 2025a</a></strong></p>

<p>We present AstroSage-LLaMA-3.1-8B, a domain-specialized natural-language AI assistant tailored for research in astronomy, astrophysics, and cosmology. Through extensive data curation, massive continued pre-training, and supervised fine-tuning, we demonstrate that proper specialization of a relatively small model can achieve performance comparable to much larger flagship models.</p>

<p>Key points:</p>
<ul>
  <li>Achieved 80.9% accuracy on the AstroMLab-1 benchmark, performing on par with GPT-4o while using only 8B parameters</li>
  <li>Demonstrated an 8-point improvement over the base LLaMA-3.1-8B model through domain specialization</li>
  <li>Maintained strong general capabilities in reasoning, mathematics, and coding despite optimization for astronomy</li>
  <li>Combined continued pre-training, supervised fine-tuning, and model merging techniques to enhance both domain expertise and instruction-following capabilities</li>
</ul>

<p><br /></p>

<h3 id="astromlab-2-astrollama-2-70b-model-and-benchmarking-specialised-llms-for-astronomy">AstroMLab 2: AstroLLaMA-2-70B Model and Benchmarking Specialised LLMs for Astronomy</h3>

<p><strong><a href="https://arxiv.org/abs/2407.11194">Rui Pan, Josh Nguyen, et al., 2024</a></strong></p>

<p>We introduce new models: AstroLLaMA-3-8B and AstroLLaMA-2-70B, building upon the previous AstroLLaMA series and quantitatively assess specialized LLMs in astronomy, leveraging recently curated high-quality astronomical MCQs.</p>

<p>Key points:</p>
<ul>
  <li>Previously released AstroLLaMA series (based on LLaMA-2-7B) underperforms compared to the native LLaMA model.</li>
  <li>Performance degradation can be partially mitigated by using high-quality data for continual pretraining.</li>
  <li>Continual pretraining on the 70B model can yield improvements, despite observed catastrophic forgetting in smaller models.</li>
</ul>

<p><br /></p>

<h3 id="astromlab-1-who-wins-astronomy-jeopardy">AstroMLab 1: Who Wins Astronomy Jeopardy!?</h3>

<p><strong><a href="https://arxiv.org/abs/2407.11194">Yuan-Sen Ting, et al., 2024, arXiv:2407.11194</a></strong></p>

<p>We present a comprehensive evaluation of proprietary and open-weights large language models using the first astronomy-specific benchmarking dataset. This dataset comprises 4,425 multiple-choice questions curated from the Annual Review of Astronomy and Astrophysics, covering a broad range of astrophysical topics.</p>

<p>Key findings:</p>
<ul>
  <li>Claude-3.5-Sonnet outperforms competitors, achieving 85.0% accuracy.</li>
  <li>Open-weights models like LLaMA-3-70b (80.6%) and Qwen-2-72b (77.7%) now compete with some of the best proprietary models.</li>
  <li>We identify performance variations across astronomical subfields, with challenges in exoplanet-related fields, stellar astrophysics, and instrumentation.</li>
  <li>Top-performing models demonstrate well-calibrated confidence, with correlations above 0.9 between confidence and correctness.</li>
  <li>The rapid progress suggests that LLM-driven research in astronomy may become feasible in the near future.</li>
</ul>

<p><br /></p>

<h3 id="legacy-output-the-astrollama-series">Legacy Output: The AstroLLaMA Series</h3>

<ol>
  <li><strong><a href="https://arxiv.org/abs/2309.06126">Josh Nguyen, et al., 2023, arXiv:2309.06126</a></strong></li>
  <li><strong><a href="https://arxiv.org/abs/2401.01916">Ernest Perkowski, Rui Pan, et al., 2024, arXiv:2401.01916</a></strong></li>
</ol>

<p>The first open-source conversational AI tool tailored for the astronomy community – AstroLLaMA-2-7B and AstroLLaMA-2-7B-Chat.</p>


      </div>
    </div>

  </body>
</html>
